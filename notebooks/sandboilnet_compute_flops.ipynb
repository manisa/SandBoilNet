{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computing FLOPS, latency and fps of a model\n",
        "\n",
        "It is important to have an idea of how to measure a video model's speed, so that you can choose the model that suits best for your use case.\n",
        "In this tutorial, we provide two simple scripts to help you compute (1) FLOPS, (2) number of parameters, (3) fps and (4) latency.\n",
        "These four numbers will help you evaluate the speed of this model.\n",
        "To be specific, FLOPS means floating point operations per second, and fps means frame per second.\n",
        "In terms of comparison, (1) FLOPS, the lower the better,\n",
        "(2) number of parameters, the lower the better,\n",
        "(3) fps, the higher the better,\n",
        "(4) latency, the lower the better.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mpanta1/.conda/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os, time, random\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import Model, Input\n",
        "from keras_flops import get_flops\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import sys; sys.path.insert(0, '..')\n",
        "from lib.metrics import jaccard, dice_coef,bce_dice_loss_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prediction(test_ids, image_path, mask_path, model):\n",
        "    # empty list to store results\n",
        "    time_taken = []\n",
        "    \n",
        "    image_path = os.path.abspath(image_path)\n",
        "    mask_path = os.path.abspath(mask_path)\n",
        "\n",
        "    # Iterating through each image in test data\n",
        "    for i in tqdm(test_ids, total=len(test_ids)):\n",
        "        filename = i\n",
        "        \n",
        "        i = os.path.join(image_path, i)\n",
        "        \n",
        "        # Load image\n",
        "        img = cv2.imread(i, cv2.IMREAD_COLOR)\n",
        "        H, W, _ = img.shape\n",
        "\n",
        "        img = cv2.resize(img, (512,512))\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0) ## (1, 256, 256, 3)\n",
        "        img = img.astype(np.float32)\n",
        "    \n",
        "        # Make prediction of mask\n",
        "        \n",
        "        start_time = time.time()\n",
        "        prediction = model.predict(img, verbose=0)[0]\n",
        "        eval_time = time.time() - start_time\n",
        "        time_taken.append(eval_time)\n",
        "        \n",
        "        # Save Mask\n",
        "        #mask = cv2.resize(prediction, (512, 512)) # (W, H)\n",
        "        #mask = mask > 0.5\n",
        "        #mask = mask * 255\n",
        "        #mask = mask.astype(np.float32)\n",
        "        #save_path = f\"{save_dir}/{filename}.png\"\n",
        "        #cv2.imwrite(save_path, mask)\n",
        "    mean_time = np.mean(time_taken)\n",
        "    mean_fps = 1/mean_time\n",
        "    print(f\"Mean Time: {mean_time:1.7f} -Mean FPS: {mean_fps:1.7f}\")\n",
        "    return mean_time, mean_fps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(model_path, model_name, pca_layer=False):\n",
        "    \n",
        "    path = os.path.join(model_path, str(model_name), \"best_model.h5\")\n",
        "    if pca_layer:\n",
        "        tf.keras.backend.clear_session()\n",
        "        with tf.keras.utils.CustomObjectScope({'jaccard':jaccard}, {'dice_coef':dice_coef}, {'tversky':'tversky'},\n",
        "                                               {'bce_dice_loss_new': bce_dice_loss_new}, {'PCALayer': PCALayer}):\n",
        "            model = tf.keras.models.load_model(path)  \n",
        "        print(f'{model_name} is loaded')\n",
        "        return model\n",
        "        \n",
        "    else:\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        with tf.keras.utils.CustomObjectScope({'jaccard':jaccard}, {'dice_coef':dice_coef}, \n",
        "                                               {'bce_dice_loss_new': bce_dice_loss_new}):\n",
        "            model = tf.keras.models.load_model(path)\n",
        "        print(f'{model_name} is loaded')\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mpanta1/usace_workspace/sandboil_research\n"
          ]
        }
      ],
      "source": [
        "img_height = 512\n",
        "img_width = 512\n",
        "root_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir + os.sep + os.pardir)\n",
        "print(root_dir)\n",
        "path_test_levee = os.path.join(root_dir,  \"datasets\", \"test_images\", \"test\") #exp2_test, pothole_test, with_grassland, #no_grassland inside \"test_images\"\n",
        "test_images = sorted(next(os.walk(path_test_levee + \"/images\"))[2])\n",
        "\n",
        "random.Random(6464).shuffle(test_images)\n",
        "\n",
        "image_path = path_test_levee + \"/images\"\n",
        "mask_path = path_test_levee + \"/masks\"\n",
        "model_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
        "model_path = os.path.join(model_dir, \"models\", \"IEEE_Access_Models_trained_on_6853images\", \"sandboilnet_variations_4e_4\") #baseline_comparision_models_4e_4\n",
        "models = os.listdir(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_dir = \"test_results\"\n",
        "if os.path.exists(save_dir):\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(save_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PCALayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_components, **kwargs):\n",
        "        super(PCALayer, self).__init__(**kwargs)\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.shape = input_shape\n",
        "        self.input_dim = int(input_shape[-1])\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=(self.input_dim, self.n_components), dtype=\"float32\",\n",
        "                                      initializer='glorot_uniform',\n",
        "                                      trainable=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Flatten the input tensor\n",
        "        #x = tf.linalg.normalize(x,axis=-1)\n",
        "        #print(x.shape)\n",
        "        # assumption is that the feature vector is normalized\n",
        "        #x = tf.math.l2_normalize(x, axis=-1)\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        flattened = tf.reshape(x, [batch_size, -1, self.input_dim])\n",
        "        \n",
        "        # Compute the mean and subtract it from the input tensor\n",
        "        mean = tf.reduce_mean(flattened, axis=1, keepdims=True)\n",
        "        centered = flattened - mean\n",
        "        \n",
        "\n",
        "        # Compute the covariance matrix\n",
        "        cov = tf.matmul(centered, centered, transpose_a=True) / tf.cast(tf.shape(flattened)[1] - 1, tf.float32)\n",
        "\n",
        "        # Compute the eigenvalues and eigenvectors of the covariance matrix\n",
        "        eigenvalues, eigenvectors = tf.linalg.eigh(cov)\n",
        "\n",
        "        # Sort the eigenvectors based on the eigenvalues\n",
        "        idx = tf.argsort(eigenvalues, axis=-1, direction='DESCENDING')\n",
        "        top_eigenvectors = tf.gather(eigenvectors, idx, batch_dims=1, axis=-1)\n",
        "        top_eigenvectors = top_eigenvectors[:, :, :self.n_components]\n",
        "\n",
        "        # Transpose the eigenvectors to match the input shape\n",
        "        top_eigenvectors = tf.transpose(top_eigenvectors, perm=[0, 1, 2])\n",
        "        \n",
        "        # Project centered data onto top principal components\n",
        "        projected = tf.matmul(centered, top_eigenvectors)\n",
        "\n",
        "        # Reshape projected data and return as output\n",
        "        output_shape = tf.concat([tf.shape(x)[:-1], [self.n_components]], axis=0)\n",
        "        #output = tf.reshape(projected, shape=(-1, *self.output_shape))\n",
        "        output = tf.reshape(projected, output_shape)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple(input_shape[:-1]) + (self.n_components,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PCALayer, self).get_config()\n",
        "        config.update({'n_components': self.n_components})\n",
        "        return config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Calculate FLOPS (Floating-Points OPerations per Second)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_flops(model, model_name):\n",
        "    flops = get_flops(model, batch_size=1)\n",
        "    with open('flops.txt', 'a') as f:\n",
        "        f.write(f\"FLOPS for {model_name}: {flops / 10 ** 9:.03} G\")\n",
        "        f.write(\"\\n\")\n",
        "        print(f\"FLOPS for {model_name}: {flops / 10 ** 9:.03} G\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names = [item for item in models if os.path.isdir(os.path.join(model_path, item))]\n",
        "#model_names = [\"SandBoilNet_Low_Dimension_PCA_bce_dice_loss_new\"]\n",
        "    \n",
        "model_list = []\n",
        "for model_name in model_names:\n",
        "    model = load_model(model_path, model_name, pca_layer=True)\n",
        "    save_flops(model, model_name)\n",
        "    tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SandBoilNet_4e_4_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:12<00:00,  4.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.1571429 -Mean FPS: 6.3636346\n",
            "SandBoilNet_SE_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:12<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.1577120 -Mean FPS: 6.3406697\n",
            "baseline_normal_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:08<00:00,  5.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.0893102 -Mean FPS: 11.1969238\n",
            "SandBoilNet_CBAM_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:12<00:00,  4.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.1634410 -Mean FPS: 6.1184145\n",
            "SandBoilNet_Low_Dimension_PCA_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:12<00:00,  4.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.1620068 -Mean FPS: 6.1725819\n",
            "Depthwise_Seepage_Inception_PCA_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:15<00:00,  3.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.2261550 -Mean FPS: 4.4217460\n",
            "SandBoilNet_Dropout_Without_PCA_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:11<00:00,  4.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.1445217 -Mean FPS: 6.9193755\n",
            "SandBoilNet_4e_4_noDropout_bce_dice_loss_new is loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [00:12<00:00,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Time: 0.1627761 -Mean FPS: 6.1434096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_names = [item for item in models if os.path.isdir(os.path.join(model_path, item))]\n",
        "for model_name in model_names:\n",
        "    model = load_model(model_path, model_name, pca_layer=True)\n",
        "    mean_time, mean_fps = prediction(test_images, os.path.abspath(image_path), os.path.abspath(mask_path), model)\n",
        "    with open('fps.csv', 'a') as f:\n",
        "        f.write(f\"{model_name},Mean Time: {mean_time:1.7f},Mean FPS: {mean_fps:1.7f}\")\n",
        "        f.write(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
